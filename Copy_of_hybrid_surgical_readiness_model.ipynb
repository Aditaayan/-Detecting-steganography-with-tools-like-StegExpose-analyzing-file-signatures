{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacAIML2023/-Detecting-steganography-with-tools-like-StegExpose-analyzing-file-signatures/blob/main/Copy_of_hybrid_surgical_readiness_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e6c70e",
      "metadata": {
        "id": "99e6c70e"
      },
      "source": [
        "# Surgical Readiness Prediction Using Hybrid ML Models\n",
        "This notebook loads a synthetic trauma dataset, performs preprocessing, and trains logistic regression, LightGBM, and LSTM models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc538209",
      "metadata": {
        "id": "dc538209"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm --quiet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "484cdce6",
      "metadata": {
        "id": "484cdce6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('synthetic_trauma_dataset.csv', parse_dates=['Timestamp'])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb387c34",
      "metadata": {
        "id": "fb387c34"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=['PatientID', 'Timestamp'], inplace=True)\n",
        "features = ['HR', 'RR', 'SpO2', 'Temp', 'Lactate', 'pH', 'BaseExcess', 'TimeSinceInjury']\n",
        "X = df[features]\n",
        "y = df['ReadyFlag']\n",
        "X.fillna(method='ffill', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a834e9bb",
      "metadata": {
        "id": "a834e9bb"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5af8199",
      "metadata": {
        "id": "a5af8199"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(max_iter=500)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33528874",
      "metadata": {
        "id": "33528874"
      },
      "outputs": [],
      "source": [
        "lgbm = LGBMClassifier()\n",
        "lgbm.fit(X_train, y_train)\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_lgbm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3015d968",
      "metadata": {
        "id": "3015d968"
      },
      "outputs": [],
      "source": [
        "# Normalize features for LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "seq_length = 10\n",
        "generator = TimeseriesGenerator(X_scaled, y.values, length=seq_length, batch_size=64)\n",
        "\n",
        "# LSTM Model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation='relu', input_shape=(seq_length, X.shape[1])),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(generator, epochs=5)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}